{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18672bdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/akv020/Tensorflow/fennomag-net/source/model2024/model_config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m MAGNETOMETER_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/akv020/Tensorflow/fennomag-net/data/XYZmagnetometer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Load model configuration\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_config.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     95\u001b[0m     model_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Load data statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/akv020/Tensorflow/fennomag-net/source/model2024/model_config.json'"
     ]
    }
   ],
   "source": [
    "# Section 1: Setup and Data Loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Define custom model components\n",
    "class CrossAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"Custom layer implementing cross-attention between two feature vectors.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_heads=4, key_dim=16, **kwargs):\n",
    "        super(CrossAttention, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.query_dense = tf.keras.layers.Dense(self.num_heads * self.key_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(self.num_heads * self.key_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(self.num_heads * self.key_dim)\n",
    "        self.output_dense = tf.keras.layers.Dense(input_shape[0][-1])\n",
    "        super(CrossAttention, self).build(input_shape)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        query, key_value = inputs\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key_value)\n",
    "        value = self.value_dense(key_value)\n",
    "        \n",
    "        batch_size = tf.shape(query)[0]\n",
    "        query = tf.reshape(query, [batch_size, 1, self.num_heads, self.key_dim])\n",
    "        key = tf.reshape(key, [batch_size, 1, self.num_heads, self.key_dim])\n",
    "        value = tf.reshape(value, [batch_size, 1, self.num_heads, self.key_dim])\n",
    "        \n",
    "        attention_scores = tf.matmul(query, key, transpose_b=True)\n",
    "        attention_scores = attention_scores / tf.math.sqrt(tf.cast(self.key_dim, tf.float32))\n",
    "        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n",
    "        \n",
    "        attention_output = tf.matmul(attention_weights, value)\n",
    "        attention_output = tf.reshape(attention_output, [batch_size, self.num_heads * self.key_dim])\n",
    "        output = self.output_dense(attention_output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(CrossAttention, self).get_config()\n",
    "        config.update({\n",
    "            'num_heads': self.num_heads,\n",
    "            'key_dim': self.key_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"Custom loss function combining MSE for each magnetic field component.\"\"\"\n",
    "    # Split predictions into components\n",
    "    be_pred, bn_pred, bu_pred = tf.unstack(y_pred, axis=1)\n",
    "    be_true, bn_true, bu_true = tf.unstack(y_true, axis=1)\n",
    "    \n",
    "    # Calculate MSE for each component\n",
    "    be_loss = tf.keras.losses.mean_squared_error(be_true, be_pred)\n",
    "    bn_loss = tf.keras.losses.mean_squared_error(bn_true, bn_pred)\n",
    "    bu_loss = tf.keras.losses.mean_squared_error(bu_true, bu_pred)\n",
    "    \n",
    "    # Weight vertical component equally\n",
    "    return be_loss + bn_loss + bu_loss\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "\n",
    "# Rest of the code remains the same...\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = \"/Users/akv020/Tensorflow/fennomag-net/source/model2024/data\"\n",
    "MODEL_DIR = \"/Users/akv020/Tensorflow/fennomag-net/source/model2024/model_outputs\"\n",
    "MAGNETOMETER_DIR = \"/Users/akv020/Tensorflow/fennomag-net/data/XYZmagnetometer\"\n",
    "\n",
    "# Load model configuration\n",
    "with open(os.path.join(MODEL_DIR, 'model_config.json'), 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "# Load data statistics\n",
    "with open(os.path.join(MODEL_DIR, 'data_statistics.json'), 'r') as f:\n",
    "    data_stats = json.load(f)\n",
    "\n",
    "# Print configuration\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"Branch 1 Lookback: {model_config['temporal_params']['branch1_lookback']} timesteps\")\n",
    "print(f\"Branch 2 Lookback: {model_config['temporal_params']['branch2_lookback']} timesteps\")\n",
    "print(f\"Forecast Horizon: {model_config['temporal_params']['forecast_horizon']} minutes\")\n",
    "print(f\"Batch Size: {model_config['temporal_params']['batch_size']}\")\n",
    "\n",
    "print(\"\\nData Statistics:\")\n",
    "print(f\"Total days: {data_stats['temporal_info']['total_days']}\")\n",
    "print(f\"Samples per day: {data_stats['temporal_info']['samples_per_day']:.2f}\")\n",
    "print(f\"Branch 1 interval: {data_stats['temporal_info']['branch1_interval']}\")\n",
    "print(f\"Branch 2 interval: {data_stats['temporal_info']['branch2_interval']}\")\n",
    "\n",
    "# Load the trained model\n",
    "print(\"\\nLoading trained model...\")\n",
    "model = tf.keras.models.load_model(\n",
    "    os.path.join(MODEL_DIR, 'best_model.h5'),\n",
    "    custom_objects={'CrossAttention': CrossAttention, 'custom_loss': custom_loss}\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# Load station coordinates\n",
    "print(\"\\nLoading station coordinates...\")\n",
    "station_coords = pd.read_csv(os.path.join(DATA_DIR, 'magnetometer/station_coordinates.csv'))\n",
    "station_coords.set_index('station', inplace=True)\n",
    "print(f\"Loaded coordinates for {len(station_coords)} stations\")\n",
    "\n",
    "# Load grid metadata\n",
    "print(\"\\nLoading grid metadata...\")\n",
    "with open(os.path.join(DATA_DIR, '2024/grid_metadata.txt'), 'r') as f:\n",
    "    grid_metadata = {}\n",
    "    for line in f:\n",
    "        key, value = line.strip().split(': ')\n",
    "        try:\n",
    "            if '[' in value and ']' in value:\n",
    "                value = value.strip('[]').split()\n",
    "                grid_metadata[key] = np.array([float(v) for v in value])\n",
    "            else:\n",
    "                grid_metadata[key] = float(value)\n",
    "        except ValueError:\n",
    "            grid_metadata[key] = value\n",
    "\n",
    "# Find station nearest to grid center\n",
    "grid_center = (grid_metadata['grid_center_lon'], grid_metadata['grid_center_lat'])\n",
    "distances = np.sqrt(\n",
    "    (station_coords['longitude'] - grid_center[0])**2 +\n",
    "    (station_coords['latitude'] - grid_center[1])**2\n",
    ")\n",
    "nearest_station = station_coords.index[distances.argmin()]\n",
    "print(f\"\\nNearest station to grid center: {nearest_station}\")\n",
    "print(f\"Distance: {distances.min():.2f} degrees\")\n",
    "print(f\"Coordinates: {station_coords.loc[nearest_station, 'longitude']:.2f}°E, \"\n",
    "      f\"{station_coords.loc[nearest_station, 'latitude']:.2f}°N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78602a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
